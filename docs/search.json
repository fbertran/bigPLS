[{"path":"https://fbertran.github.io/bigPLScox/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Frederic Bertrand. Maintainer, author. Myriam Maumy-Bertrand. Author.","code":""},{"path":"https://fbertran.github.io/bigPLS/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Frederic Bertrand Myriam Maumy-Bertrand (2025). Partial Least Squares Regression extension big data, R package version 0.5.0.","code":"@Manual{,   title = {Partial Least Squares Regression and their extension for big data},   author = {F. Bertrand and M. Maumy-Bertrand},   publisher = {manual},   year = {2025},   note = {R package version 0.5.0},   url = {https://fbertran.github.io/homepage/}, }"},{"path":[]},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"frédéric-bertrand-and-myriam-maumy-bertrand","dir":"","previous_headings":"","what":"Frédéric Bertrand and Myriam Maumy-Bertrand","title":"Partial Least Squares Regression and their extension for big data","text":"goal bigPLS provide Cox models high dimensional setting R. Support parallel computation GPU developed. website examples created F. Bertrand M. Maumy-Bertrand.","code":""},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Partial Least Squares Regression and their extension for big data","text":"can install released version bigPLS CRAN : can install development version bigPLS github :","code":"install.packages(\"bigPLS\") devtools::install_github(\"fbertran/bigPLS\")"},{"path":[]},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"the-dataset","dir":"","previous_headings":"Allelotyping real dataset","what":"The dataset","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"library(plsRcox) data(micro.censure) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80] Y_test_micro <- micro.censure$survyear[81:117] C_test_micro <- micro.censure$DC[81:117]  data(Xmicro.censure_compl_imp) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro)  X_train_micro_orig <- Xmicro.censure_compl_imp[1:80,] X_train_micro_orig_df <- data.frame(X_train_micro_orig)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"compute-deviance-residuals-with-some-options","dir":"","previous_headings":"Allelotyping real dataset","what":"Compute deviance residuals with some options.","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"head(computeDR(Y_train_micro,C_train_micro,plot=TRUE))"},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"generate-dataset","dir":"","previous_headings":"Simulated data","what":"Generate dataset","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"set.seed(4669) library(bigPLS) x_sim <- matrix(sample(0:1, size = 20000, replace = TRUE), ncol = 2) dCox_sim <- dataCox(10^4, lambda = 3, rho = 2, x_sim, beta = c(1,3), cens.rate = 5) data(dCox_sim)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"compute-deviance-residuals-with-some-options-1","dir":"","previous_headings":"Simulated data","what":"Compute deviance residuals with some options.","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"with(dCox_sim,head(computeDR(time,status,plot=TRUE)))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"model-matrix","dir":"","previous_headings":"Simulated data","what":"Model Matrix","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"coxgpls(~.,Y_train_micro,C_train_micro,ncomp=6,trace=TRUE,model_matrix=TRUE,dataXplan = X_train_micro_orig_df,ind.block.x=c(3,10,20))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"coxgpls","dir":"","previous_headings":"Simulated data","what":"coxgpls","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"(cox_gpls_fit=coxgpls(X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15)))  (cox_gpls_fit2=coxgpls(~X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15)))  (cox_gpls_fit3=coxgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15)))  rm(cox_gpls_fit,cox_gpls_fit2,cox_gpls_fit3)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cvcoxgpls","dir":"","previous_headings":"Simulated data","what":"cv.coxgpls","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"set.seed(123456) (cv.coxgpls.res=cv.coxgpls(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),nt=10,ind.block.x=c(3,10,15)))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"coxgplsdr","dir":"","previous_headings":"Simulated data","what":"coxgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"(cox_gplsDR_fit=coxgplsDR(X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15)))  (cox_gplsDR_fit2=coxgplsDR(~X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15)))  (cox_gplsDR_fit3=coxgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15)))  rm(cox_gplsDR_fit,cox_gplsDR_fit2,cox_gplsDR_fit3)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cvcoxgplsdr","dir":"","previous_headings":"Simulated data","what":"cv.coxgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"set.seed(123456)  (cv.coxsplsDR.res=cv.coxgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),nt=10,ind.block.x=c(3,10,15)))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"coxdkgplsdr","dir":"","previous_headings":"Simulated data","what":"coxDKgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"(cox_DKsplsDR_fit=coxDKgplsDR(X_train_micro,Y_train_micro,C_train_micro,ncomp=6, validation=\"CV\",ind.block.x=c(3,10,15),verbose=TRUE))  (cox_DKsplsDR_fit=coxDKgplsDR(~X_train_micro,Y_train_micro,C_train_micro,ncomp=6, validation=\"CV\",ind.block.x=c(3,10,15)))  (cox_DKsplsDR_fit=coxDKgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, validation=\"CV\",dataXplan=data.frame(X_train_micro),ind.block.x=c(3,10,15)))  rm(cox_DKsplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cvcoxdkgplsdr","dir":"","previous_headings":"Simulated data","what":"cv.coxDKgPLSDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"set.seed(123456)  (cv.coxDKgplsDR.res=cv.coxDKgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),nt=10,ind.block.x=c(3,10,15)))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"coxsgpls","dir":"","previous_headings":"Simulated data","what":"coxsgpls","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"(cox_sgpls_fit=coxsgpls(X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6)))  (cox_sgpls_fit2=coxsgpls(~X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6)))  (cox_sgpls_fit3=coxsgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6)))  rm(cox_sgpls_fit,cox_sgpls_fit2,cox_sgpls_fit3)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cvcoxsgpls","dir":"","previous_headings":"Simulated data","what":"cv.coxsgpls","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"set.seed(123456) (cv.coxsgpls.res=cv.coxsgpls(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),nt=10,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 10)))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"coxsgplsdr","dir":"","previous_headings":"Simulated data","what":"coxsgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"(cox_sgplsDR_fit=coxsgplsDR(X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 10)))  (cox_sgplsDR_fit2=coxsgplsDR(~X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 10)))  (cox_sgplsDR_fit3=coxsgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6,                            dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 10)))  rm(cox_sgplsDR_fit,cox_sgplsDR_fit2,cox_sgplsDR_fit3)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cvcoxsgplsdr","dir":"","previous_headings":"Simulated data","what":"cv.coxsgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"set.seed(4669)  (cv.coxsgplsDR.res=cv.coxsgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),nt=10,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 10)))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"coxdksgplsdr","dir":"","previous_headings":"Simulated data","what":"coxDKsgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"(cox_DKsgplsDR_fit=coxDKsgplsDR(X_train_micro,Y_train_micro,C_train_micro,ncomp=6, validation=\"CV\",ind.block.x=c(3,10,15), alpha.x = rep(0.95, 10),verbose=TRUE))  (cox_DKsgplsDR_fit=coxDKsgplsDR(~X_train_micro,Y_train_micro,C_train_micro,ncomp=6, validation=\"CV\",ind.block.x=c(3,10,15), alpha.x = rep(0.95, 10)))  (cox_DKsgplsDR_fit=coxDKsgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6,                               validation=\"CV\",dataXplan=data.frame(X_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 10)))  rm(cox_DKsgplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cvcoxdkgplsdr-1","dir":"","previous_headings":"Simulated data","what":"cv.coxDKgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"set.seed(123456)  (cv.coxDKgplsDR.res=cv.coxDKgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),nt=10,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 10)))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"coxspls_sgpls","dir":"","previous_headings":"Simulated data","what":"coxspls_sgpls","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"(cox_coxspls_sgpls_fit=coxspls_sgpls(X_train_micro,Y_train_micro,C_train_micro,ncomp=6,keepX = rep(5, 6)))  (cox_coxspls_sgpls_fit2=coxspls_sgpls(~X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.keepX = rep(5, 6)))  (cox_coxspls_sgpls_fit3=coxspls_sgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,keepX = rep(5, 6)))  rm(cox_coxspls_sgpls_fit,cox_coxspls_sgpls_fit2,cox_coxspls_sgpls_fit3)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cvcoxspls_sgpls","dir":"","previous_headings":"Simulated data","what":"cv.coxspls_sgpls","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"set.seed(123456) (cv.coxspls_sgpls.res=cv.coxspls_sgpls(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),nt=10, keepX = rep(5, 10)))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"coxspls_sgplsdr","dir":"","previous_headings":"Simulated data","what":"coxspls_sgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"(cox_spls_sgplsDR_fit=coxspls_sgplsDR(X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15)))  (cox_spls_sgplsDR_fit2=coxspls_sgplsDR(~X_train_micro,Y_train_micro,C_train_micro,ncomp=6,ind.block.x=c(3,10,15)))  (cox_spls_sgplsDR_fit3=coxspls_sgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6,                            dataXplan=X_train_micro_df,ind.block.x=c(3,10,15)))  rm(cox_spls_sgplsDR_fit,cox_spls_sgplsDR_fit2,cox_spls_sgplsDR_fit3)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cvcoxspls_sgplsdr","dir":"","previous_headings":"Simulated data","what":"cv.coxspls_sgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"set.seed(123456)  (cv.coxspls_sgplsDR.res=cv.coxspls_sgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),nt=10,ind.block.x=c(3,10,15)))"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"coxdkspls_sgplsdr","dir":"","previous_headings":"Simulated data","what":"coxDKspls_sgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"","code":"(cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(X_train_micro,Y_train_micro,C_train_micro,ncomp=6, validation=\"CV\",ind.block.x=c(3,10,15),verbose=TRUE))  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(~X_train_micro,Y_train_micro,C_train_micro,ncomp=6, validation=\"CV\",ind.block.x=c(3,10,15)))  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6,                               validation=\"CV\",dataXplan=data.frame(X_train_micro),ind.block.x=c(3,10,15)))  rm(cox_DKspls_sgplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cvcoxdkspls_sgplsdr","dir":"","previous_headings":"Simulated data","what":"cv.coxDKspls_sgplsDR","title":"Partial Least Squares Regression and their extension for big data","text":"https://stackoverflow.com/questions/49959260/removing-columns--big-matrix----one-value","code":"set.seed(123456)  (cv.coxDKspls_sgplsDR.res=cv.coxDKspls_sgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),nt=10,ind.block.x=c(3,10,15))) data(survData, package=\"bigSurvSGD\") resultsBigscale <- bigscale(formula=Surv(time, status)~.,data=survData, parallel.flag=TRUE, num.cores=2) resultsBigscale  # Simulated survival data to be read off the memory data(survData) # a dataset with 1000 observations (rows) and 10 features (columns) # Save dataset survSGD as bigSurvSGD to be read chunk-by-chunk off the memory  write.csv(survData, file.path(tempdir(), \"bigSurvData.csv\"), row.names = FALSE)  dataPath <- file.path(tempdir(), \"bigSurvData.csv\") # path to where data is resultsBigscaleOffMemory <- bigscale(formula=Surv(time, status)~., data=dataPath,  bigmemory.flag=TRUE, parallel.flag=TRUE, num.cores=2) resultsBigscaleOffMemory   # Simulated sparse survival data data(sparseSurvData,package=\"bigSurvSGD\") # a sparse data with 100 observations (rows) and 150 features (columns) resultsBigscaleSparse <- bigscale(formula=Surv(time, status)~.,data=sparseSurvData, parallel.flag=TRUE, num.cores=2) resultsBigscaleSparse    # Simulated survival data - just estimation and no confidence interval data(survData) # a dataset with 1000 observations (rows) and 10 features (columns) resultsBig <- bigSurvSGD::bigSurvSGD(formula=Surv(time, status)~.,data=survData, inference.method=\"none\", parallel.flag=TRUE, num.cores=2, features.mean = resultsBigscale$features.mean, features.sd = resultsBigscale$features.sd) (resultsBig$coef)  # Simulated survival data to be read off the memory data(survData) # a dataset with 1000 observations (rows) and 10 features (columns) # Save dataset survSGD as bigSurvSGD to be read chunk-by-chunk off the memory  write.csv(survData, file.path(tempdir(), \"bigSurvData.csv\"), row.names = FALSE)  dataPath <- file.path(tempdir(), \"bigSurvData.csv\") # path to where data is resultsBigOffMemory <- bigSurvSGD::bigSurvSGD(formula=Surv(time, status)~., data=dataPath,  bigmemory.flag=TRUE, parallel.flag=TRUE, num.cores=2, features.mean = resultsBigscale$features.mean, features.sd = resultsBigscale$features.sd)  #much faster without tests, inference.method=\"none\") (resultsBigOffMemory$coef)   # Simulated sparse survival data data(sparseSurvData) # a sparse data with 100 observations (rows) and 150 features (columns) resultsBigSparse <- bigSurvSGD::bigSurvSGD(formula=Surv(time, status)~.,data=sparseSurvData,  alpha=0.9, lambda=0.1, features.mean = resultsBigscale$features.mean, features.sd = resultsBigscale$features.sd) (resultsBigSparse$coef) #data(survData, package = \"bigSurvSGD\") #survData[2,3] <- NA #write.csv(survData, \"~/Documents/GitHub/bigPLS/bigSurvData.csv\", row.names = FALSE)  datapath0_NA = path.expand(\"~/Documents/GitHub/bigPLS/add_data/bigSurvData_NA.csv\")  library(bigPLS) if(FALSE){ resultsBigscale <- bigscale(formula=Surv(time, status)~., data=datapath0_NA,bigmemory.flag=TRUE, parallel.flag=TRUE, num.cores=2) resultsBigscale }  # First PLS step -> compute weights  ind.col=1 name.col.all <-(colnames(read.csv(datapath0_NA,nrows=2,header=TRUE))[-c(1,2)]) name.col0 = name.col.all[ind.col] partialbigSurvSGDv0(datapath = datapath0_NA, resBigscale=resultsBigscale, name.col=name.col0)  # Need to filter for missing values pairwise  simplify2array(lapply(name.col.all,partialbigSurvSGDv0, datapath=datapath0_NA, resBigscale=resultsBigscale, bigmemory.flag=FALSE)) simplify2array(lapply(name.col.all,partialbigSurvSGDv0, datapath=datapath0_NA, resBigscale=resultsBigscale, bigmemory.flag=TRUE))  #install.packages(\"bigalgebra\") #library(\"bigalgebra\")  datapath0 = path.expand(\"~/Documents/GitHub/bigPLS/add_data/bigSurvData.csv\")  library(bigPLS)  debug(bigPLS:::bigplsRcoxmodel.default)    bigPLS::bigplsRcox(formula=Surv(time, status)~.,data=datapath0,verbose=TRUE)  bigPLS::bigplsRcox(formula=Surv(time, status)~.,data=datapath0, backingfile=\"temp_plsRcox_file2.bin\", backingpath=path.expand(\"~/Documents/GitHub/bigPLS/add_data/\"),  descriptorfile=\"temp_plsRcox_file2.desc\",verbose=TRUE)  bigPLS::bigplsRcox(formula=Surv(time, status)~.,data=NULL,descriptorfile=\"temp_plsRcox_file.desc\", backingpath=path.expand(\"~/Documents/GitHub/bigPLS/add_data/\"),verbose=TRUE) # Simulated survival data - just estimation and no confidence interval data(survData) # a dataset with 1000 observations (rows) and 10 features (columns)   resultsBig <- bigSurvSGD::bigSurvSGD(formula=Surv(time, status)~.,data=survData, inference.method=\"none\", parallel.flag=TRUE, num.cores=2, features.mean = resultsBigscale$features.mean, features.sd = resultsBigscale$features.sd) (resultsBig$coef) #install.packages(\"bigstatsr\") library(bigstatsr) library(bigassertr) library(bigparallelr)  X <- big_attachExtdata()  # No scaling big_noscale <- big_scale(center = FALSE, scale = FALSE) class(big_noscale) # big_scale returns a new function str(big_noscale(X)) big_noscale2 <- big_scale(center = FALSE) str(big_noscale2(X)) # you can't scale without centering  # Centering big_center <- big_scale(scale = FALSE) str(big_center(X)) str(big_scale()(X))  dim(X) rows_along(X) cols_along(X)  seq_range(c(3, 10))  X <- big_attachExtdata()  test <- big_parallelize(X, p.FUN = partialbigSurvSGD, p.combine = 'rbind', ncores = 2)"},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"bigpls","dir":"","previous_headings":"","what":"bigPLS","title":"Partial Least Squares Regression and their extension for big data","text":"PLS regression (linear) generalized linear regression (glm) big data","code":""},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"cox","dir":"","previous_headings":"","what":"Cox","title":"Partial Least Squares Regression and their extension for big data","text":"plsRcox","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"glm-pls","dir":"","previous_headings":"","what":"glm PLS","title":"Partial Least Squares Regression and their extension for big data","text":"imputePLS Final fit model.","code":""},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"big-data-cox-via-sgd","dir":"","previous_headings":"","what":"big data Cox (via SGD)","title":"Partial Least Squares Regression and their extension for big data","text":"bigSurvSGD","code":""},{"path":"https://fbertran.github.io/bigPLS/index.html","id":"sgd-cox","dir":"","previous_headings":"","what":"SGD cox","title":"Partial Least Squares Regression and their extension for big data","text":"coxphSGD","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/Xmicro.censure_compl_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Imputed Microsat features — Xmicro.censure_compl_imp","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"dataset provides imputed microsat specifications. Imputations computed using Multivariate Imputation Chained Equations (MICE) using predictive mean matching numeric columns, logistic regression imputation binary data factors 2 levels polytomous regression imputation categorical data .e. factors three levels.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/Xmicro.censure_compl_imp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"data frame 117 observations following 40 variables. D18S61 numeric vector D17S794 numeric vector D13S173 numeric vector D20S107 numeric vector TP53 numeric vector D9S171 numeric vector D8S264 numeric vector D5S346 numeric vector D22S928 numeric vector D18S53 numeric vector D1S225 numeric vector D3S1282 numeric vector D15S127 numeric vector D1S305 numeric vector D1S207 numeric vector D2S138 numeric vector D16S422 numeric vector D9S179 numeric vector D10S191 numeric vector D4S394 numeric vector D1S197 numeric vector D6S264 numeric vector D14S65 numeric vector D17S790 numeric vector D5S430 numeric vector D3S1283 numeric vector D4S414 numeric vector D8S283 numeric vector D11S916 numeric vector D2S159 numeric vector D16S408 numeric vector D6S275 numeric vector D10S192 numeric vector sexe numeric vector Agediag numeric vector Siege numeric vector T numeric vector N numeric vector M numeric vector STADE factor levels 0 1 2 3 4","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/Xmicro.censure_compl_imp.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"Allelotyping identification genomic alterations rectal chromosomally unstable tumors without preoperative treatment, Benoît Romain, Agnès Neuville, Nicolas Meyer, Cécile Brigand, Serge Rohr, Anne Schneider, Marie-Pierre Gaub Dominique Guenot, BMC Cancer 2010, 10:561, doi:10.1186/1471-2407-10-561.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/Xmicro.censure_compl_imp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/Xmicro.censure_compl_imp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"","code":"# \\donttest{ data(Xmicro.censure_compl_imp) X_train_micro <- Xmicro.censure_compl_imp[1:80,] X_test_micro <- Xmicro.censure_compl_imp[81:117,] rm(X_train_micro,X_test_micro) # }"},{"path":"https://fbertran.github.io/bigPLS/reference/bigPLS-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bigPLS-package — bigPLS-package","title":"bigPLS-package — bigPLS-package","text":"Provides Partial least squares Regression regular, generalized linear Cox models big data. allows missing data explanatory variables. Repeated k-fold cross-validation models using various criteria. Bootstrap confidence intervals constructions also available.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigPLS-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"bigPLS-package — bigPLS-package","text":"TODO","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/bigPLS-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bigPLS-package — bigPLS-package","text":"Maintainer: Frederic Bertrand frederic.bertrand@lecnam.net (ORCID) Authors: Myriam Maumy-Bertrand myriam.maumy@ehesp.fr (ORCID)","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigPLS-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bigPLS-package — bigPLS-package","text":"","code":"set.seed(314) library(bigPLS) data(sim_data) head(sim_data) #>                    status         X1         X2         X3        X4         X5 #> 0.0013236229370777      1  0.5448667 -0.9205711  1.1017160 1.3558567  1.4346174 #> 0.193665925040523       1 -0.5641483  0.2733279  0.9731780 1.1232252  0.2652977 #> 0.0167866701431944      1  1.4921118  0.2598002 -1.5436997 0.1165158  1.2208183 #> 0.0584127055299712      1 -0.6430141 -0.9807448 -1.2294945 0.8006227  1.5492078 #> 0.732960708716205       1  0.1876928 -1.2571263  0.9016827 1.3562191 -1.6809553 #> 0.508483386474255       0 -0.6141516 -0.8162560  0.2633415 0.4188066  0.2791399 #>                            X6         X7         X8          X9        X10 #> 0.0013236229370777 -0.8727406  1.5161252  0.7801527 -0.53617252 -0.6990319 #> 0.193665925040523   1.5046047  0.9096495 -1.2200395 -1.57280359  0.8347194 #> 0.0167866701431944 -0.6451659  1.2515692  0.5867273 -0.20080821  0.7492891 #> 0.0584127055299712  1.2557210  0.6188920  0.7123894 -0.67379538 -1.2377412 #> 0.732960708716205   0.7304366 -1.1223302  0.9633307  0.14016470 -0.9996676 #> 0.508483386474255  -0.0538974 -0.1410697 -0.8637916  0.01669784  1.5589135"},{"path":"https://fbertran.github.io/bigPLS/reference/bigSurvSGD.na.omit.html","id":null,"dir":"Reference","previous_headings":"","what":"Adapt bigSurvSGD to use na.omit — bigSurvSGD.na.omit","title":"Adapt bigSurvSGD to use na.omit — bigSurvSGD.na.omit","text":"Adapt bigSurvSGD use na.omit","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigSurvSGD.na.omit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adapt bigSurvSGD to use na.omit — bigSurvSGD.na.omit","text":"","code":"bigSurvSGD.na.omit(   formula = Surv(time = time, status = status) ~ .,   data,   norm.method = \"standardize\",   features.mean = NULL,   features.sd = NULL,   opt.method = \"AMSGrad\",   beta.init = NULL,   beta.type = \"averaged\",   lr.const = 0.12,   lr.tau = 0.5,   strata.size = 20,   batch.size = 1,   num.epoch = 100,   b1 = 0.9,   b2 = 0.99,   eps = 1e-08,   inference.method = \"plugin\",   num.boot = 1000,   num.epoch.boot = 100,   boot.method = \"SGD\",   lr.const.boot = 0.12,   lr.tau.boot = 0.5,   num.sample.strata = 1000,   sig.level = 0.05,   beta0 = 0,   alpha = NULL,   lambda = NULL,   nlambda = 100,   num.strata.lambda = 10,   lambda.scale = 1,   parallel.flag = FALSE,   num.cores = NULL,   bigmemory.flag = FALSE,   num.rows.chunk = 1e+06,   col.names = NULL,   type = \"float\" )"},{"path":"https://fbertran.github.io/bigPLS/reference/bigSurvSGD.na.omit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adapt bigSurvSGD to use na.omit — bigSurvSGD.na.omit","text":"formula  data  norm.method  features.mean  features.sd  opt.method  beta.init  beta.type  lr.const  lr.tau  strata.size  batch.size  num.epoch  b1  b2  eps  inference.method  num.boot  num.epoch.boot  boot.method  lr.const.boot  lr.tau.boot  num.sample.strata  sig.level  beta0  alpha  lambda  nlambda  num.strata.lambda  lambda.scale  parallel.flag  num.cores  bigmemory.flag  num.rows.chunk  col.names  type","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigSurvSGD.na.omit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adapt bigSurvSGD to use na.omit — bigSurvSGD.na.omit","text":"coef: Log hazards ratio. inference used, returns vector estimated coefficients: inference used, returns matrix including estimates confidence intervals coefficients. case penalization, resturns matrix columns corresponding lambdas. coef.exp: Exponentiated version coef (hazards ratio). lambda: Returns lambda(s) used penalizarion. alpha: Returns alpha used penalizarion. features.mean: Returns means features, given calculated features.sd: Returns standard deviations features, given calculated.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/bigSurvSGD.na.omit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adapt bigSurvSGD to use na.omit — bigSurvSGD.na.omit","text":"","code":"#' set.seed(314) library(sim_data) #> Error in library(sim_data): there is no package called ‘sim_data’"},{"path":"https://fbertran.github.io/bigPLS/reference/bigplsRcox.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares Regression generalized linear models — bigplsRcox","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"function implements extension Partial least squares Regression Cox Models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigplsRcox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"","code":"bigplsRcox(formula, data, ...)  bigplsRcoxmodel(formula, data, ...)  # Default S3 method bigplsRcoxmodel(   formula = Surv(time = time, status = status) ~ .,   data,   deepcopy_data = TRUE,   scale.X = TRUE,   scale.Y = TRUE,   nt = 2,   type = \"double\",   allres = TRUE,   verbose = TRUE,   backingfile = NULL,   backingpath = NULL,   descriptorfile = NULL,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/bigplsRcox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"... arguments pass plsRmodel.default plsRmodel.formula nt number components extracted type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. verbose details displayed ? Xplan formula matrix eXplanatory variables (training) dataset time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? limQ2set limit value Q2 dataPredictY predictor(s) (testing) dataset pvals.expli individual p-values reported tune model selection ? alpha.pvals.expli level significance predictors pvals.expli=TRUE tol_Xi minimal value Norm2(Xi) \\(\\mathrm{det}(pp' \\times pp)\\) missing value dataX. defaults \\(10^{-12}\\) weights optional vector 'prior weights' used fitting process. NULL numeric vector. subset optional vector specifying subset observations used fitting process. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxDKplsDR called. model_frame TRUE, model frame returned. method method used fitting model. default method \"glm.fit\" uses iteratively reweighted least squares (IWLS). User-supplied fitting functions can supplied either function character string naming function, function takes arguments glm.fit. control list parameters controlling fitting process. glm.fit passed glm.control. sparse coefficients non-significant predictors (<alpha.pvals.expli) set 0 sparseStop component extraction stop significant predictors (<alpha.pvals.expli) found model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigplsRcox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"Depends model used fit model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigplsRcox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"typical predictor form response ~ terms response (numeric) response vector terms series terms specifies linear predictor response. terms specification form first + second indicates terms first together terms second duplicates removed. specification form first:second indicates set terms obtained taking interactions terms first terms second. specification first*second indicates cross first second. first + second + first:second. terms formula re-ordered main effects come first, followed interactions, second-order, third-order : avoid pass terms object formula. Non-NULL weights can used indicate different observations different dispersions (values weights inversely proportional dispersions); equivalently, elements weights positive integers w_i, response y_i mean w_i unit-weight observations.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigplsRcox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"bigplsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/bigplsRcox.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigplsRcox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  bigplsRcox(X_train_micro,time=Y_train_micro,event=C_train_micro,nt=5) #> ____************************************************____ #> Using big matrix without backing and descriptor files #> Error in (function (cond) .Internal(C_tryCatchHelper(addr, 1L, cond)))(structure(list(message = \"argument \\\"data\\\" is missing, with no default\",     call = bigplsRcoxmodel.default(X_train_micro, time = Y_train_micro,         event = C_train_micro, nt = 5)), class = c(\"getvarError\", \"missingArgError\", \"error\", \"condition\"))): error in evaluating the argument 'filename' in selecting a method for function 'read.big.matrix': argument \"data\" is missing, with no default bigplsRcox(~X_train_micro,time=Y_train_micro,event=C_train_micro,nt=5) #> ____************************************************____ #> Using big matrix without backing and descriptor files #> Error in (function (cond) .Internal(C_tryCatchHelper(addr, 1L, cond)))(structure(list(message = \"argument \\\"data\\\" is missing, with no default\",     call = bigplsRcoxmodel.default(~X_train_micro, time = Y_train_micro,         event = C_train_micro, nt = 5)), class = c(\"getvarError\", \"missingArgError\", \"error\", \"condition\"))): error in evaluating the argument 'filename' in selecting a method for function 'read.big.matrix': argument \"data\" is missing, with no default  bigplsRcox(Xplan=X_train_micro,time=Y_train_micro,event=C_train_micro,nt=5,sparse=TRUE, alpha.pvals.expli=.15) #> ____************************************************____ #> Using big matrix without backing and descriptor files #> Error in (function (cond) .Internal(C_tryCatchHelper(addr, 1L, cond)))(structure(list(message = \"argument \\\"data\\\" is missing, with no default\",     call = bigplsRcoxmodel.default(Xplan = X_train_micro, time = Y_train_micro,         event = C_train_micro, nt = 5, sparse = TRUE, alpha.pvals.expli = 0.15)), class = c(\"getvarError\", \"missingArgError\", \"error\", \"condition\"))): error in evaluating the argument 'filename' in selecting a method for function 'read.big.matrix': argument \"data\" is missing, with no default bigplsRcox(Xplan=~X_train_micro,time=Y_train_micro,event=C_train_micro,nt=5,sparse=TRUE, alpha.pvals.expli=.15) #> ____************************************************____ #> Using big matrix without backing and descriptor files #> Error in (function (cond) .Internal(C_tryCatchHelper(addr, 1L, cond)))(structure(list(message = \"argument \\\"data\\\" is missing, with no default\",     call = bigplsRcoxmodel.default(Xplan = ~X_train_micro, time = Y_train_micro,         event = C_train_micro, nt = 5, sparse = TRUE, alpha.pvals.expli = 0.15)), class = c(\"getvarError\", \"missingArgError\", \"error\", \"condition\"))): error in evaluating the argument 'filename' in selecting a method for function 'read.big.matrix': argument \"data\" is missing, with no default"},{"path":"https://fbertran.github.io/bigPLS/reference/bigscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — bigscale","title":"Title — bigscale","text":"Title","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — bigscale","text":"","code":"bigscale(   formula = Surv(time = time, status = status) ~ .,   data,   norm.method = \"standardize\",   strata.size = 20,   batch.size = 1,   features.mean = NULL,   features.sd = NULL,   parallel.flag = FALSE,   num.cores = NULL,   bigmemory.flag = FALSE,   num.rows.chunk = 1e+06,   col.names = NULL,   type = \"short\" )"},{"path":"https://fbertran.github.io/bigPLS/reference/bigscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — bigscale","text":"formula  data  norm.method  strata.size  batch.size  features.mean  features.sd  parallel.flag  num.cores  bigmemory.flag  num.rows.chunk  col.names  type","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigscale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Title — bigscale","text":"object scaler class   time.indices: indices time variable   cens.indices: indices censored variables   features.indices: indices features   time.sd: standard deviation time variable   time.mean: mean time variable   features.sd: standard deviation features   features.mean: mean features   nr: number rows   nc: number columns   col.names: columns names","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/bigscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Title — bigscale","text":"","code":"1+1 #> [1] 2"},{"path":"https://fbertran.github.io/bigPLS/reference/computeDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute deviance residuals — computeDR","title":"Compute deviance residuals — computeDR","text":"function computes residuals null model fit using coxph function mixOmics's package. Since computation use explanatory variables, likely doable even big dat without dedicated framework.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/computeDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute deviance residuals — computeDR","text":"","code":"computeDR(   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleY = TRUE,   plot = FALSE )"},{"path":"https://fbertran.github.io/bigPLS/reference/computeDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute deviance residuals — computeDR","text":"time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleY time values standardized ? plot survival function plotted ?","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/computeDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute deviance residuals — computeDR","text":"Residuals null model fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/computeDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute deviance residuals — computeDR","text":"TODO","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/computeDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute deviance residuals — computeDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/computeDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute deviance residuals — computeDR","text":"","code":"library(plsRcox) data(micro.censure)  Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  Y_DR <- computeDR(Y_train_micro,C_train_micro) Y_DR <- computeDR(Y_train_micro,C_train_micro,plot=TRUE)"},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"","code":"coxDKgplsDR(Xplan, ...)  # S3 method for class 'formula' coxDKgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )  # Default S3 method coxDKgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. kernel kernel function used training predicting. parameter can set function, class kernel, computes inner product feature space two vector arguments (see kernels). kernlab package provides popular kernel functions can used setting kernel parameter following strings: list(\"rbfdot\") Radial Basis kernel \"Gaussian\" list(\"polydot\") Polynomial kernel list(\"vanilladot\") Linear kernel list(\"tanhdot\") Hyperbolic tangent kernel list(\"laplacedot\") Laplacian kernel list(\"besseldot\") Bessel kernel list(\"anovadot\") ANOVA RBF kernel list(\"splinedot\") Spline kernel hyperkernel list hyper-parameters (kernel parameters). list contains parameters used kernel function. valid parameters existing kernels : sigma, inverse kernel width Radial Basis kernel function \"rbfdot\" Laplacian kernel \"laplacedot\". degree, scale, offset Polynomial kernel \"polydot\". scale, offset Hyperbolic tangent kernel function \"tanhdot\". sigma, order, degree Bessel kernel \"besseldot\". sigma, degree ANOVA kernel \"anovadot\". case Radial Basis kernel function (Gaussian) Laplacian kernel, hyperkernel missing, heuristics sigest used calculate good sigma value data. verbose details displayed ?","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"allres=FALSE : cox_DKgplsDR Final Cox-model. allres=TRUE : tt_DKgplsDR PLSR components. cox_DKgplsDR Final Cox-model. DKgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxDKgplsDR_fit=coxDKgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>            coef exp(coef)  se(coef)     z       p #> dim.1 2.960e+00 1.930e+01 1.131e+00 2.618 0.00885 #> dim.2 8.638e+00 5.642e+03 2.772e+00 3.117 0.00183 #> dim.3 6.140e+00 4.641e+02 2.153e+00 2.852 0.00434 #> dim.4 1.691e+01 2.210e+07 5.529e+00 3.059 0.00222 #> dim.5 3.985e+00 5.378e+01 2.087e+00 1.910 0.05618 #> dim.6 1.086e+01 5.188e+04 4.053e+00 2.679 0.00739 #>  #> Likelihood ratio test=68.13  on 6 df, p=9.859e-13 #> n= 80, number of events= 17  (coxDKgplsDR_fit=coxDKgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>            coef exp(coef)  se(coef)     z       p #> dim.1 2.927e+00 1.866e+01 1.120e+00 2.612 0.00899 #> dim.2 8.411e+00 4.496e+03 2.699e+00 3.116 0.00183 #> dim.3 5.886e+00 3.599e+02 2.055e+00 2.864 0.00419 #> dim.4 1.648e+01 1.434e+07 5.383e+00 3.061 0.00221 #> dim.5 3.903e+00 4.957e+01 2.062e+00 1.893 0.05840 #> dim.6 1.076e+01 4.729e+04 4.059e+00 2.652 0.00801 #>  #> Likelihood ratio test=67.43  on 6 df, p=1.373e-12 #> n= 80, number of events= 17  (coxDKgplsDR_fit=coxDKgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>            coef exp(coef)  se(coef)     z       p #> dim.1 2.987e+00 1.982e+01 1.139e+00 2.622 0.00875 #> dim.2 8.799e+00 6.630e+03 2.825e+00 3.115 0.00184 #> dim.3 6.322e+00 5.566e+02 2.224e+00 2.843 0.00447 #> dim.4 1.721e+01 2.968e+07 5.631e+00 3.056 0.00225 #> dim.5 4.041e+00 5.688e+01 2.104e+00 1.921 0.05474 #> dim.6 1.091e+01 5.491e+04 4.050e+00 2.695 0.00704 #>  #> Likelihood ratio test=68.61  on 6 df, p=7.876e-13 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit) #> Warning: object 'cox_spls_sgpls_fit' not found"},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgplsDR perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"","code":"coxDKsgplsDR(Xplan, ...)  # S3 method for class 'formula' coxDKsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )  # Default S3 method coxDKsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x mixing parameter (value 0 1) related sparsity within group X dataset. upper.lambda default upper.lambda=10^5. large value specifying upper bound intervall lambda values searching value tuning parameter (lambda) corresponding non-zero group variables. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. kernel kernel function used training predicting. parameter can set function, class kernel, computes inner product feature space two vector arguments (see kernels). kernlab package provides popular kernel functions can used setting kernel parameter following strings: list(\"rbfdot\") Radial Basis kernel \"Gaussian\" list(\"polydot\") Polynomial kernel list(\"vanilladot\") Linear kernel list(\"tanhdot\") Hyperbolic tangent kernel list(\"laplacedot\") Laplacian kernel list(\"besseldot\") Bessel kernel list(\"anovadot\") ANOVA RBF kernel list(\"splinedot\") Spline kernel hyperkernel list hyper-parameters (kernel parameters). list contains parameters used kernel function. valid parameters existing kernels : sigma, inverse kernel width Radial Basis kernel function \"rbfdot\" Laplacian kernel \"laplacedot\". degree, scale, offset Polynomial kernel \"polydot\". scale, offset Hyperbolic tangent kernel function \"tanhdot\". sigma, order, degree Bessel kernel \"besseldot\". sigma, degree ANOVA kernel \"anovadot\". case Radial Basis kernel function (Gaussian) Laplacian kernel, hyperkernel missing, heuristics sigest used calculate good sigma value data. verbose details displayed ?","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"allres=FALSE : cox_sgplsDR Final Cox-model. allres=TRUE : tt_sgplsDR PLSR components. cox_sgplsDR Final Cox-model. sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxDKsgplsDR_fit=coxDKsgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxDKsgplsDR_fit=coxDKsgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxDKsgplsDR_fit=coxDKsgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_sgplsDR_sgfit) #> Warning: object 'cox_sgplsDR_sgfit' not found"},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"","code":"coxDKspls_sgplsDR(Xplan, ...)  # S3 method for class 'formula' coxDKspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )  # Default S3 method coxDKspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. kernel kernel function used training predicting. parameter can set function, class kernel, computes inner product feature space two vector arguments (see kernels). kernlab package provides popular kernel functions can used setting kernel parameter following strings: list(\"rbfdot\") Radial Basis kernel \"Gaussian\" list(\"polydot\") Polynomial kernel list(\"vanilladot\") Linear kernel list(\"tanhdot\") Hyperbolic tangent kernel list(\"laplacedot\") Laplacian kernel list(\"besseldot\") Bessel kernel list(\"anovadot\") ANOVA RBF kernel list(\"splinedot\") Spline kernel hyperkernel list hyper-parameters (kernel parameters). list contains parameters used kernel function. valid parameters existing kernels : sigma, inverse kernel width Radial Basis kernel function \"rbfdot\" Laplacian kernel \"laplacedot\". degree, scale, offset Polynomial kernel \"polydot\". scale, offset Hyperbolic tangent kernel function \"tanhdot\". sigma, order, degree Bessel kernel \"besseldot\". sigma, degree ANOVA kernel \"anovadot\". case Radial Basis kernel function (Gaussian) Laplacian kernel, hyperkernel missing, heuristics sigest used calculate good sigma value data. verbose details displayed ? ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"allres=FALSE : cox_DKspls_sgplsDR Final Cox-model. allres=TRUE : tt_DKspls_sgplsDR PLSR components. cox_DKspls_sgplsDR Final Cox-model. DKspls_sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxDKspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKspls_sgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1    10.667 42914.514     2.324 4.589 4.45e-06 #> dim.2    11.108 66675.205     2.661 4.174 2.99e-05 #> dim.3     7.363  1577.198     2.309 3.189  0.00143 #> dim.4     9.851 18969.562     3.000 3.284  0.00102 #> dim.5     3.143    23.177     2.500 1.257  0.20874 #> dim.6     8.193  3617.282     3.515 2.331  0.01974 #>  #> Likelihood ratio test=45.06  on 6 df, p=4.55e-08 #> n= 80, number of events= 17  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKspls_sgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1    10.498 36233.569     2.293 4.579 4.68e-06 #> dim.2    10.959 57451.012     2.621 4.181 2.91e-05 #> dim.3     7.284  1456.980     2.269 3.210 0.001329 #> dim.4     9.826 18509.661     2.956 3.324 0.000886 #> dim.5     2.991    19.906     2.456 1.218 0.223284 #> dim.6     8.234  3767.230     3.404 2.419 0.015570 #>  #> Likelihood ratio test=45.27  on 6 df, p=4.145e-08 #> n= 80, number of events= 17  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKspls_sgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1    10.399 32837.329     2.275 4.571 4.84e-06 #> dim.2    10.873 52745.257     2.599 4.184 2.87e-05 #> dim.3     7.242  1396.713     2.248 3.222 0.001275 #> dim.4     9.816 18317.798     2.931 3.349 0.000812 #> dim.5     2.902    18.205     2.431 1.194 0.232600 #> dim.6     8.259  3860.869     3.340 2.472 0.013424 #>  #> Likelihood ratio test=45.39  on 6 df, p=3.921e-08 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_DKspls_sgplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLS/reference/coxgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group PLSR components — coxgpls","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"","code":"coxgpls(Xplan, ...)  # S3 method for class 'formula' coxgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/coxgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"allres=FALSE : cox_gpls Final Cox-model. allres=TRUE : tt_gpls PLSR components. cox_gpls Final Cox-model. gpls_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/coxgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxgpls_fit=coxgpls(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,keepX=rep(4,6))) #> Error in coxgpls.default(X_train_micro, Y_train_micro, C_train_micro,     ncomp = 6, keepX = rep(4, 6)): argument \"ind.block.x\" is missing, with no default (coxgpls_fit=coxgpls(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,keepX=rep(4,6))) #> Error in coxgpls.default(~X_train_micro, Y_train_micro, C_train_micro,     ncomp = 6, keepX = rep(4, 6)): argument \"ind.block.x\" is missing, with no default (ccoxgpls_fit=coxgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,keepX=rep(4,6))) #> Error in coxgpls.default(~., Y_train_micro, C_train_micro, ncomp = 6,     dataXplan = X_train_micro_df, keepX = rep(4, 6)): argument \"ind.block.x\" is missing, with no default  rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit) #> Warning: object 'cox_spls_sgpls_fit' not found"},{"path":"https://fbertran.github.io/bigPLS/reference/coxgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"","code":"coxgplsDR(Xplan, ...)  # S3 method for class 'formula' coxgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/coxgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"allres=FALSE : cox_gplsDR Final Cox-model. allres=TRUE : tt_gplsDR PLSR components. cox_gplsDR Final Cox-model. gplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/coxgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxgplsDR_fit=coxgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7784    2.1781   0.1987 3.917 8.96e-05 #> dim.2 0.9626    2.6186   0.2982 3.228  0.00125 #> dim.3 0.9110    2.4868   0.4075 2.236  0.02536 #> dim.4 0.9022    2.4650   0.4004 2.253  0.02424 #> dim.5 0.1844    1.2026   0.2664 0.692  0.48865 #> dim.6 0.7448    2.1059   0.4228 1.761  0.07819 #>  #> Likelihood ratio test=54.95  on 6 df, p=4.745e-10 #> n= 80, number of events= 17  (coxgplsDR_fit=coxgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7784    2.1781   0.1987 3.917 8.96e-05 #> dim.2 0.9626    2.6186   0.2982 3.228  0.00125 #> dim.3 0.9110    2.4868   0.4075 2.236  0.02536 #> dim.4 0.9022    2.4650   0.4004 2.253  0.02424 #> dim.5 0.1844    1.2026   0.2664 0.692  0.48865 #> dim.6 0.7448    2.1059   0.4228 1.761  0.07819 #>  #> Likelihood ratio test=54.95  on 6 df, p=4.745e-10 #> n= 80, number of events= 17  (coxgplsDR_fit=coxgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7784    2.1781   0.1987 3.917 8.96e-05 #> dim.2 0.9626    2.6186   0.2982 3.228  0.00125 #> dim.3 0.9110    2.4868   0.4075 2.236  0.02536 #> dim.4 0.9022    2.4650   0.4004 2.253  0.02424 #> dim.5 0.1844    1.2026   0.2664 0.692  0.48865 #> dim.6 0.7448    2.1059   0.4228 1.761  0.07819 #>  #> Likelihood ratio test=54.95  on 6 df, p=4.745e-10 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit) #> Warning: object 'cox_spls_sgpls_fit' not found"},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"","code":"coxsgpls(Xplan, ...)  # S3 method for class 'formula' coxsgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxsgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x mixing parameter (value 0 1) related sparsity within group X dataset. upper.lambda default upper.lambda=10^5. large value specifying upper bound intervall lambda values searching value tuning parameter (lambda) corresponding non-zero group variables. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"allres=FALSE : cox_sgpls Final Cox-model. allres=TRUE : tt_sgpls PLSR components. cox_sgpls Final Cox-model. sgpls_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxsgpls_fit=coxsgpls(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (coxsgpls_fit=coxsgpls(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (coxsgpls_fit=coxsgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_sgpls_sgfit) #> Warning: object 'cox_sgpls_sgfit' not found"},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgplsDR perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"","code":"coxsgplsDR(Xplan, ...)  # S3 method for class 'formula' coxsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x mixing parameter (value 0 1) related sparsity within group X dataset. upper.lambda default upper.lambda=10^5. large value specifying upper bound intervall lambda values searching value tuning parameter (lambda) corresponding non-zero group variables. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"allres=FALSE : cox_sgplsDR Final Cox-model. allres=TRUE : tt_sgplsDR PLSR components. cox_sgplsDR Final Cox-model. sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxsgplsDR_fit=coxsgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxsgplsDR_fit=coxsgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxsgplsDR_fit=coxsgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_sgplsDR_sgfit) #> Warning: object 'cox_sgplsDR_sgfit' not found"},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"","code":"coxspls_sgpls(Xplan, ...)  # S3 method for class 'formula' coxspls_sgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxspls_sgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"allres=FALSE : cox_spls_sgpls Final Cox-model. allres=TRUE : tt_spls_sgpls PLSR components. cox_spls_sgpls Final Cox-model. spls_sgpls_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (cox_spls_sgpls_fit=coxspls_sgpls(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgpls) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.295124  0.744439  0.260495 -1.133 0.2572 #> dim.2 -0.652196  0.520901  0.323480 -2.016 0.0438 #> dim.3 -0.445224  0.640681  0.278859 -1.597 0.1104 #> dim.4 -0.069023  0.933305  0.276956 -0.249 0.8032 #> dim.5  0.044924  1.045948  0.275060  0.163 0.8703 #> dim.6 -0.005691  0.994325  0.303281 -0.019 0.9850 #>  #> Likelihood ratio test=8.81  on 6 df, p=0.1845 #> n= 80, number of events= 17  (cox_spls_sgpls_fit=coxspls_sgpls(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgpls) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.295124  0.744439  0.260495 -1.133 0.2572 #> dim.2 -0.652196  0.520901  0.323480 -2.016 0.0438 #> dim.3 -0.445224  0.640681  0.278859 -1.597 0.1104 #> dim.4 -0.069023  0.933305  0.276956 -0.249 0.8032 #> dim.5  0.044924  1.045948  0.275060  0.163 0.8703 #> dim.6 -0.005691  0.994325  0.303281 -0.019 0.9850 #>  #> Likelihood ratio test=8.81  on 6 df, p=0.1845 #> n= 80, number of events= 17  (cox_spls_sgpls_fit=coxspls_sgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgpls) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.295124  0.744439  0.260495 -1.133 0.2572 #> dim.2 -0.652196  0.520901  0.323480 -2.016 0.0438 #> dim.3 -0.445224  0.640681  0.278859 -1.597 0.1104 #> dim.4 -0.069023  0.933305  0.276956 -0.249 0.8032 #> dim.5  0.044924  1.045948  0.275060  0.163 0.8703 #> dim.6 -0.005691  0.994325  0.303281 -0.019 0.9850 #>  #> Likelihood ratio test=8.81  on 6 df, p=0.1845 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit)"},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"","code":"coxspls_sgplsDR(Xplan, ...)  # S3 method for class 'formula' coxspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"allres=FALSE : cox_spls_sgplsDR Final Cox-model. allres=TRUE : tt_spls_sgplsDR PLSR components. cox_spls_sgplsDR Final Cox-model. spls_sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/coxspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (cox_spls_sgplsDR_fit=coxspls_sgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgplsDR) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.295124  0.744439  0.260495 -1.133 0.2572 #> dim.2 -0.652196  0.520901  0.323480 -2.016 0.0438 #> dim.3 -0.445224  0.640681  0.278859 -1.597 0.1104 #> dim.4 -0.069023  0.933305  0.276956 -0.249 0.8032 #> dim.5  0.044924  1.045948  0.275060  0.163 0.8703 #> dim.6 -0.005691  0.994325  0.303281 -0.019 0.9850 #>  #> Likelihood ratio test=8.81  on 6 df, p=0.1845 #> n= 80, number of events= 17  (cox_spls_sgplsDR_fit=coxspls_sgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgplsDR) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.295124  0.744439  0.260495 -1.133 0.2572 #> dim.2 -0.652196  0.520901  0.323480 -2.016 0.0438 #> dim.3 -0.445224  0.640681  0.278859 -1.597 0.1104 #> dim.4 -0.069023  0.933305  0.276956 -0.249 0.8032 #> dim.5  0.044924  1.045948  0.275060  0.163 0.8703 #> dim.6 -0.005691  0.994325  0.303281 -0.019 0.9850 #>  #> Likelihood ratio test=8.81  on 6 df, p=0.1845 #> n= 80, number of events= 17  (cox_spls_sgplsDR_fit=coxspls_sgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgplsDR) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.295124  0.744439  0.260495 -1.133 0.2572 #> dim.2 -0.652196  0.520901  0.323480 -2.016 0.0438 #> dim.3 -0.445224  0.640681  0.278859 -1.597 0.1104 #> dim.4 -0.069023  0.933305  0.276956 -0.249 0.8032 #> dim.5  0.044924  1.045948  0.275060  0.163 0.8703 #> dim.6 -0.005691  0.994325  0.303281 -0.019 0.9850 #>  #> Likelihood ratio test=8.81  on 6 df, p=0.1845 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"function cross-validates coxDKgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"","code":"cv.coxDKgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"data list three items: x explanatory variables passed coxDKgplsDR's Xplan argument, time passed coxDKgplsDR's time argument, status coxDKgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxDKgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxDKgplsDR.res=cv.coxDKgplsDR(list(x=X_train_micro,time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15),nt=2)) #> Kernel :  rbfdot  #> Estimated_sigma  0.01257168  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Kernel :  rbfdot  #> Estimated_sigma  0.01198263  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Kernel :  rbfdot  #> Estimated_sigma  0.01156809  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Kernel :  rbfdot  #> Estimated_sigma  0.01287851  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Kernel :  rbfdot  #> Estimated_sigma  0.01127231  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 2 #>  #> $cv.error10 #> [1] 0.5000000 0.6381540 0.6963262 #>  #> $cv.se10 #> [1] 0.00000000 0.03036225 0.02912723 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"function cross-validates coxDKsgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"","code":"cv.coxDKsgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"data list three items: x explanatory variables passed coxDKsgplsDR's Xplan argument, time passed coxDKsgplsDR's time argument, status coxDKsgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxDKsgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) if (FALSE) { # \\dontrun{ (cv.coxDKsgplsDR.res=cv.coxDKsgplsDR(list(x=X_train_micro,time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=3)) } # }"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"function cross-validates coxDKspls_sgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"","code":"cv.coxDKspls_sgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"data list three items: x explanatory variables passed coxDKspls_sgplsDR's Xplan argument, time passed coxDKspls_sgplsDR's time argument, status coxDKspls_sgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxDKspls_sgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxDKspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxDKspls_sgplsDR.res=cv.coxDKspls_sgplsDR(list(x=X_train_micro,time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15),nt=3)) #> Kernel :  rbfdot  #> Estimated_sigma  0.01257168  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Kernel :  rbfdot  #> Estimated_sigma  0.01198263  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Kernel :  rbfdot  #> Estimated_sigma  0.01156809  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Kernel :  rbfdot  #> Estimated_sigma  0.01287851  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Kernel :  rbfdot  #> Estimated_sigma  0.01127231  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.6880595 0.8043289 0.7553747 #>  #> $cv.se10 #> [1] 0.00000000 0.03137597 0.03833047 0.02937653 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"function cross-validates coxgpls models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"","code":"cv.coxgpls(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"data list three items: x explanatory variables passed coxgpls's Xplan argument, time passed coxgpls's time argument, status coxgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxgpls.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxgpls.res=cv.coxgpls(list(x=X_train_micro,time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.5225223 0.6037656 0.5639968 #>  #> $cv.se10 #> [1] 0.00000000 0.05032449 0.04012942 0.03493106 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"function cross-validates coxgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"","code":"cv.coxgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"data list three items: x explanatory variables passed coxgpls's Xplan argument, time passed coxgpls's time argument, status coxgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxgpls.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxgplsDR.res=cv.coxgplsDR(list(x=X_train_micro,time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.6786893 0.6913293 0.6485690 #>  #> $cv.se10 #> [1] 0.00000000 0.04017423 0.02726346 0.03897730 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"function cross-validates coxsgpls models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"","code":"cv.coxsgpls(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"data list three items: x explanatory variables passed coxsgpls's Xplan argument, time passed coxsgpls's time argument, status coxsgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxsgpls.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxsgpls.res=cv.coxsgpls(list(x=X_train_micro,time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.4217599 0.5382923 0.5519544 #>  #> $cv.se10 #> [1] 0.00000000 0.03195833 0.02746499 0.03490158 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 3 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"function cross-validates coxsgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"","code":"cv.coxsgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"data list three items: x explanatory variables passed coxsgplsDR's Xplan argument, time passed coxsgplsDR's time argument, status coxsgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxsgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxsgplsDR.res=cv.coxsgplsDR(list(x=X_train_micro,time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=2)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 2 #>  #> $cv.error10 #> [1] 0.5000000 0.6856847 0.6944862 #>  #> $cv.se10 #> [1] 0.00000000 0.03282521 0.03554813 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"function cross-validates coxspls_sgpls models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"","code":"cv.coxspls_sgpls(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"data list three items: x explanatory variables passed coxspls_sgpls's Xplan argument, time passed coxspls_sgpls's time argument, status coxspls_sgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxspls_sgpls.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxspls_sgpls.res=cv.coxspls_sgpls(list(x=X_train_micro,time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.5178023 0.4063418 0.4953083 #>  #> $cv.se10 #> [1] 0.00000000 0.05438761 0.01486926 0.04950516 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 1 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"function cross-validates coxspls_sgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"","code":"cv.coxspls_sgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"data list three items: x explanatory variables passed coxspls_sgplsDR's Xplan argument, time passed coxspls_sgplsDR's time argument, status coxspls_sgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxspls_sgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/cv.coxspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxspls_sgplsDR.res=cv.coxspls_sgplsDR(list(x=X_train_micro,time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.5178023 0.4063418 0.4953083 #>  #> $cv.se10 #> [1] 0.00000000 0.05438761 0.01486926 0.04950516 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 1 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLS/reference/dataCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"Function dataCox generaters random survivaldata Weibull distribution (parameters lambda rho given input x data, model coefficients beta censoring rate censoring comes exponential distribution parameter cens.rate.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/dataCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"","code":"dataCox(n, lambda, rho, x, beta, cens.rate)"},{"path":"https://fbertran.github.io/bigPLS/reference/dataCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"n Number observations generate. lambda lambda parameter Weibull distribution. rho rho parameter Weibull distribution. x data.frame input data generate survival times . beta True model coefficients. cens.rate Parameter exponential distribution, responsible censoring.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/dataCox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"data.frame containing columns: id integer. time survival times. status observation status (event occured (1) (0)). x data.frame input data generate survival times .","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/dataCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"observation true survival time generated censroing time. censoring time less survival time, survival time returned status observations set 0 means observation censored time. survival time less censoring time, observation true survival time returned status observation set 1 means event noticed.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/dataCox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"http://onlinelibrary.wiley.com/doi/10.1002/sim.2059/abstract Generating survival times simulate Cox proportional hazards models, 2005 Ralf Bender, Thomas Augustin, Maria Blettner.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/dataCox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"","code":"if (FALSE) { # \\dontrun{ x <- matrix(sample(0:1, size = 20000, replace = TRUE), ncol = 2) dCox <- dataCox(10^4, lambda = 3, rho = 2, x, beta = c(1,3), cens.rate = 5)  } # }"},{"path":"https://fbertran.github.io/bigPLS/reference/internal-bigPLS.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal bigPLS functions — internal-bigPLS","title":"Internal bigPLS functions — internal-bigPLS","text":"called user.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/internal-bigPLS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal bigPLS functions — internal-bigPLS","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/internal-bigPLS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Internal bigPLS functions — internal-bigPLS","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/micro.censure.html","id":null,"dir":"Reference","previous_headings":"","what":"Microsat features and survival times — micro.censure","title":"Microsat features and survival times — micro.censure","text":"dataset provides Microsat specifications survival times.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/micro.censure.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Microsat features and survival times — micro.censure","text":"data frame 117 observations following 43 variables. numpat factor levels B1006 B1017 B1028 B1031 B1046 B1059 B1068 B1071 B1102 B1115 B1124 B1139 B1157 B1161 B1164 B1188 B1190 B1192 B1203 B1211 B1221 B1225 B1226 B1227 B1237 B1251 B1258 B1266 B1271 B1282 B1284 B1285 B1286 B1287 B1290 B1292 B1298 B1302 B1304 B1310 B1319 B1327 B1353 B1357 B1363 B1368 B1372 B1373 B1379 B1388 B1392 B1397 B1403 B1418 B1421t1 B1421t2 B1448 B1451 B1455 B1460 B1462 B1466 B1469 B1493 B1500 B1502 B1519 B1523 B1529 B1530 B1544 B1548 B500 B532 B550 B558 B563 B582 B605 B609 B634 B652 B667 B679 B701 B722 B728 B731 B736 B739 B744 B766 B771 B777 B788 B800 B836 B838 B841 B848 B871 B873 B883 B889 B912 B924 B925 B927 B938 B952 B954 B955 B968 B972 B976 B982 B984 D18S61 numeric vector D17S794 numeric vector D13S173 numeric vector D20S107 numeric vector TP53 numeric vector D9S171 numeric vector D8S264 numeric vector D5S346 numeric vector D22S928 numeric vector D18S53 numeric vector D1S225 numeric vector D3S1282 numeric vector D15S127 numeric vector D1S305 numeric vector D1S207 numeric vector D2S138 numeric vector D16S422 numeric vector D9S179 numeric vector D10S191 numeric vector D4S394 numeric vector D1S197 numeric vector D6S264 numeric vector D14S65 numeric vector D17S790 numeric vector D5S430 numeric vector D3S1283 numeric vector D4S414 numeric vector D8S283 numeric vector D11S916 numeric vector D2S159 numeric vector D16S408 numeric vector D6S275 numeric vector D10S192 numeric vector sexe numeric vector Agediag numeric vector Siege numeric vector T numeric vector N numeric vector M numeric vector STADE factor levels 0 1 2 3 4 survyear numeric vector DC numeric vector","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/micro.censure.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Microsat features and survival times — micro.censure","text":"Allelotyping identification genomic alterations rectal chromosomally unstable tumors without preoperative treatment, #' Benoît Romain, Agnès Neuville, Nicolas Meyer, Cécile Brigand, Serge Rohr, Anne Schneider, Marie-Pierre Gaub Dominique Guenot, BMC Cancer 2010, 10:561, doi:10.1186/1471-2407-10-561.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/micro.censure.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Microsat features and survival times — micro.censure","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/micro.censure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Microsat features and survival times — micro.censure","text":"","code":"# \\donttest{ data(micro.censure) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80] Y_test_micro <- micro.censure$survyear[81:117] C_test_micro <- micro.censure$DC[81:117] rm(Y_train_micro,C_train_micro,Y_test_micro,C_test_micro) # }"},{"path":"https://fbertran.github.io/bigPLS/reference/partialbigSurvSGDv0.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — partialbigSurvSGDv0","title":"Title — partialbigSurvSGDv0","text":"Title","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/partialbigSurvSGDv0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — partialbigSurvSGDv0","text":"","code":"partialbigSurvSGDv0(   name.col,   datapath,   ncores = 1,   resBigscale = resultsBigscale,   bigmemory.flag = FALSE,   parallel.flag = FALSE,   inf.mth = \"none\" )"},{"path":"https://fbertran.github.io/bigPLS/reference/partialbigSurvSGDv0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — partialbigSurvSGDv0","text":"name.col  datapath  ncores  resBigscale  bigmemory.flag  inf.mth","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/partialbigSurvSGDv0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Title — partialbigSurvSGDv0","text":"coefres: Log hazards ratio. inference used, returns vector estimated coefficients: inference used, returns matrix including estimates confidence intervals coefficients. case penalization, resturns matrix columns corresponding lambdas.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/reference/partialbigSurvSGDv0.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Title — partialbigSurvSGDv0","text":"","code":"1+1 #> [1] 2"},{"path":"https://fbertran.github.io/bigPLS/reference/pls_big.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares for bigmemory matrices — pls_big","title":"Partial least squares for bigmemory matrices — pls_big","text":"`pls_big()` fits partial least squares (PLS) model using NIPALS algorithm implemented C++ operates directly [bigmemory::big.matrix] inputs. -memory file-backed matrices supported. `matrixpls_stream_bigmatrix()` pure R fallback performs computation streaming chunks file-backed `big.matrix` without loading fully memory.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/pls_big.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares for bigmemory matrices — pls_big","text":"","code":"pls_big(   X,   Y,   ncomp = 2L,   tol = 1e-06,   max_iter = 500L,   stream = FALSE,   num.rows.chunk = 1e+06,   backingfile = NULL,   backingpath = NULL,   descriptorfile = NULL,   type = \"double\",   ... )  matrixpls_stream_bigmatrix(   X,   Y,   ncomp = 2L,   tol = 1e-06,   max_iter = 500L,   num.rows.chunk = 1e+06,   ... )"},{"path":"https://fbertran.github.io/bigPLS/reference/pls_big.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares for bigmemory matrices — pls_big","text":"X Either `bigmemory::big.matrix`, `bigmemory::big.matrix.descriptor`, character path delimited file can read [bigmemory::read.big.matrix()]. Y Numeric response matrix matching number rows. Vectors coerced one-column matrix. ncomp Number latent components extract. tol Convergence tolerance iterative updates. max_iter Maximum number iterations NIPALS inner loop. stream Logical; `TRUE`, force chunk-wise R implementation via [matrixpls_stream_bigmatrix()]. num.rows.chunk Number rows load per chunk `stream = TRUE`. backingfile, backingpath, descriptorfile Optional arguments passed [bigmemory::read.big.matrix()] `X` file path. type Storage mode use reading file path, defaulting `\"double\"`. ... Reserved future extensions.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/pls_big.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial least squares for bigmemory matrices — pls_big","text":"list containing   * `scores`: X-score matrix (`T`)   * `Yscores`: Y-score matrix (`U`)   * `weights`: weight matrix (`W`)   * `loadings`: X-loading matrix (`P`)   * `Yloadings`: Y-loading matrix (`Q`)   * `coefficients`: regression coefficients linking `T` `U`","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/sim_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated dataset — sim_data","title":"Simulated dataset — sim_data","text":"dataset provides explantory variables simulations censoring status. dataset provides explantory variables simulations censoring status.","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/sim_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated dataset — sim_data","text":"data frame 1000 observations following 11 variables. status binary vector X1 numeric vector X2 numeric vector X3 numeric vector X4 numeric vector X5 numeric vector X6 numeric vector X7 numeric vector X8 numeric vector X9 numeric vector X10 numeric vector data frame 10000 observations following 5 variables. id integer vector time numeric vector status binary vector x.1 binary vector x.2 binary vector","code":""},{"path":"https://fbertran.github.io/bigPLS/reference/sim_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated dataset — sim_data","text":"TODO. TODO.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLS/news/index.html","id":"bigpls-040","dir":"Changelog","previous_headings":"","what":"bigPLS 0.4.0","title":"bigPLS 0.4.0","text":"Maintainer email update Added unit tests","code":""},{"path":"https://fbertran.github.io/bigPLS/news/index.html","id":"bigpls-030","dir":"Changelog","previous_headings":"","what":"bigPLS 0.3.0","title":"bigPLS 0.3.0","text":"Code update","code":""},{"path":"https://fbertran.github.io/bigPLS/news/index.html","id":"bigpls-020","dir":"Changelog","previous_headings":"","what":"bigPLS 0.2.0","title":"bigPLS 0.2.0","text":"Improving code help pages","code":""},{"path":"https://fbertran.github.io/bigPLS/news/index.html","id":"bigpls-010","dir":"Changelog","previous_headings":"","what":"bigPLS 0.1.0","title":"bigPLS 0.1.0","text":"Implementing gpls, sgpls based models","code":""},{"path":"https://fbertran.github.io/bigPLS/news/index.html","id":"bigpls-001","dir":"Changelog","previous_headings":"","what":"bigPLS 0.0.1","title":"bigPLS 0.0.1","text":"Package creation","code":""}]
